# text =   Вчера OpenAI выпустили Whisper.
# relations = "Application_hasAuthor_Organization 0 0"
Вчера O
OpenAI B-Organization
выпустили B-Application_hasAuthor_Organization
Whisper B-Application
. O

# text =   По сути авторы попытались: Исключить транскрипты других систем ASR из датасета; Привести пунктуации к некому стандарту.
# relations = ""
По O
сути O
авторы O
попытались O
: O
Исключить O
транскрипты O
других O
систем O
ASR B-Application
из O
датасета O
; O
Привести O
пунктуации O
к O
некому O
стандарту O
. O

# text =   Серьезной нормализации или денормализации текста не делалось.
# relations = ""
Серьезной O
нормализации B-Method
или O
денормализации B-Method
текста O
не O
делалось O
. O

# text =   Под капотом же seq2seq модель, глядишь сама всё и так выучит.
# relations = ""
Под O
капотом O
же O
seq2seq B-Model
модель O
, O
глядишь O
сама O
всё O
и O
так O
выучит O
. O

# text =   Ведь исходя из названий FAIR, OpenAI и прочие же FOSS - альтруисты, борющиеся за наше будущее, они же выложили код для тренировки (а повторить смогут лишь GAFA компании) и все датасеты, не так ли?
# relations = ""
Ведь O
исходя O
из O
названий O
FAIR B-Organization
, O
OpenAI B-Organization
и O
прочие O
же O
FOSS B-Organization
- O
альтруисты O
, O
борющиеся O
за O
наше O
будущее O
, O
они O
же O
выложили O
код O
для O
тренировки O
( O
а O
повторить O
смогут O
лишь O
GAFA B-Organization
компании O
) O
и O
все O
датасеты O
, O
не O
так O
ли O
? O

# text =   На практике OpenAI уже давно не Open, а недавняя история с DALLE-2 / Midjourney / Stable Diffusion скорее иллюстрируют тренд.
# relations = "Model_hasAuthor_Organization 0 0, Model_hasAuthor_Organization 1 0, Model_hasAuthor_Organization 2 0"
На O
практике O
OpenAI B-Organization
уже O
давно O
не O
Open O
, O
а O
недавняя O
история O
с O
DALLE-2 B-Model
/ O
Midjourney B-Model
/ O
Stable B-Model
Diffusion I-Model
скорее O
иллюстрируют O
тренд O
. O

# text =   Наверное стоит только сказать, что это sequence-to-sequence encoder-decoder трансформерная модель, без особого снижения длины инпута с довольном стандартным окном в 25 миллисекунд и шагом в 10 миллисекунд, работающая на аудио в 16 килогерц.
# relations = ""
Наверное O
стоит O
только O
сказать O
, O
что O
это O
sequence B-Model
- I-Model
to I-Model
- I-Model
sequence I-Model
encoder I-Model
- I-Model
decoder I-Model
трансформерная O
модель O
, O
без O
особого O
снижения O
длины O
инпута O
с O
довольном O
стандартным O
окном O
в O
25 O
миллисекунд O
и O
шагом O
в O
10 O
миллисекунд O
, O
работающая O
на O
аудио O
в O
16 O
килогерц O
. O

# text =   Решать конечно вам для вашего конкретного приложения, но если сравнивать только саму модель распознавания, а не весь обвес в виде сервиса (понятно, что тут VAD и детектор языка запихали тоже в модель), например с древними бенчмарками из silero-models, то самые маленькие модели на CPU в расчете на 1 ядро (1 ядро = 2 потока) отличаются по скорости … на два порядка.
# relations = ""
Решать O
конечно O
вам O
для O
вашего O
конкретного O
приложения O
, O
но O
если O
сравнивать O
только O
саму O
модель O
распознавания O
, O
а O
не O
весь O
обвес O
в O
виде O
сервиса O
( O
понятно O
, O
что O
тут O
VAD B-Method
и O
детектор O
языка O
запихали O
тоже O
в O
модель O
) O
, O
например O
с O
древними O
бенчмарками O
из O
silero B-Model
- I-Model
models I-Model
, O
то O
самые O
маленькие O
модели O
на O
CPU O
в O
расчете O
на O
1 O
ядро O
( O
1 O
ядро O
= O
2 O
потока O
) O
отличаются O
по O
скорости O
… O
на O
два O
порядка O
. O

# text =   Для наших моделей из прошлого релиза, многие из этих датасетов тоже как бы "zero-shot" (то есть у нас нет соответствующего большого тренировочного датасета).
# relations = ""
Для O
наших O
моделей O
из O
прошлого O
релиза O
, O
многие O
из O
этих O
датасетов O
тоже O
как O
бы O
" O
zero B-Method_ML
- I-Method_ML
shot I-Method_ML
" O
( O
то O
есть O
у O
нас O
нет O
соответствующего O
большого O
тренировочного O
датасета O
) O
. O
