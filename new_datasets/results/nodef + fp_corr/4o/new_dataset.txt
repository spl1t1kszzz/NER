В O
задаче B-Task
классификации I-Task
использовался O
logloss B-Metric
, O
вычисляемый O
как O
среднее O
значение O
метрики O
sklearn B-Metric
. I-Metric
metrics I-Metric
. I-Metric
log_loss I--Metric
по O
классам O
болезней O
. O
Также O 
на O 
описанном O 
материале O 
строятся O 
более O 
сложные O 
темы O 
, O 
такие O 
как O 
вариационные B-Model
автокодировщики I-Model
( O 
Kingma B-Person
and I-Person
Welling I-Person
, O 
2013 O 
) O 
, O 
нейробайесовские B-Method
методы I-Method
( O 
Müller B-Person
et I-Person
al I-Person
. O 
, O 
2021 O 
) O 
и O 
даже O 
некоторые O 
теории O 
сознания O 
( O 
Friston B-Person
et I-Person
al I-Person
. O 
, O 
2022 O 
) O 
. O 
В O
этой O
статье O
я O
расскажу O
все O
, O
что O
вам O
нужно O
знать O
про O
ALBERT B-Model
, O
RoBERTa B-Model
, O
и O
DistilBERT B-Model
. O
Если O
непонятно O
по O
названию O
, O
эти O
модели O
— O
модифицированные O
версии O
оригинального O
современного O
трансформера O
BERT B-Model
. O
Эти O
три O
модели O
из O
библиотеки O
Hugging B-InfoResource
Face I-InfoResource
O —
O самые
O популярные
O на
O сегодняшний
O день
. O
Я O
рассмотрю O
их O
сходства O
и O
различия O
по O
сравнению O
друг O
с O
другом O
и O
добавлю O
фрагменты O
кода O
. O
Они O
покажут O
, O
как O
вы O
можете O
их O
использовать O
. O
Поэтому O
MSE B-Metric
, O
в O
сравнении O
с O
MAE B-Metric
, O
не O
так O
сильно O
штрафует O
несущественные O
ошибки O
, O
но O
сильнее O
штрафует O
большие O
ошибки O
. O
Это O
и O
есть O
тот O
самый O
переход O
количества O
в O
качество O
, O
про O
который O
нам O
когда O
‑ O
то O
твердил O
старина O
Карл B-Person
Маркс I-Person
. O
Python B-Lang
служит O
главным O
инструментом O
в O
руках O
data B-Science
scientists I-Science
, O
не O
имеет O
строгой O
типизации O
и O
предназначен O
для O
быстрой O
разработки O
прототипов O
или O
написания O
коротких O
сценариев O
или O
скриптов O
. O
Крупные O
компании O
также O
принимают O
участие O
в O
разработке O
библиотек O
для O
NLP B-Subject
, O
как O  
например O  
NLP B-Application  
Architect I-Application  
от O  
Intel B-Organization  
или O  
PyTorch B-Application  
от O  
исследователей O  
из O  
Facebook B-Organization  
и O  
Uber B-Organization  
. O
Казалось O
бы O
, O
здесь O
напрашивается O
оценка B-Metric
точности I-Metric
( O
accuracy B-Metric
) O
— O
считаем O
, O
сколько O
раз O
мы O
попали O
из O
общего O
количества O
случаев O
. O
Если O
у O
нас O
есть O
5 O
слов O
и O
для O
4 O
мы O
правильно O
определили O
вершину O
, O
то O
получаем O
80 O
% O
. O
Январь O
2022 O
: O
InstructGPT B-Model
, O
или O
как O
научить O
робота O
быть O
политкорректым O
. O
На O
самом O
деле O
, O
увеличение O
размеров O
языковых B-Lang
моделей I-Lang
само O
по O
себе O
еще O
не O
означает O
, O
что O
они O
будут O
отвечать O
на O
запросы O
именно O
так O
, O
как O
хочет O
их O
пользователь O
. O
Ведь O
часто O
мы O
, O
когда O
формулируем O
какой O
‑ O
то O
запрос O
, O
подразумеваем O
очень O
много O
скрытых O
условий O
— O
которые O
в O
коммуникации O
между O
людьми O
считаются O
сами O
собой O
разумеющимися O
, O
что O
ли O
. O
А O
вот O  
GPT	B-Model
-	I-Model
2	I-Model
никто O  
специально O  
таким O  
трюкам O  
не O  
учил O  
; O  
но O  
она O  
взяла O  
, O  
и O  
сама O  
неожиданно O  
и O  
уверенно O  
превзошла O  
своих O  
« O  
специализированных O  
» O  
предшественников O  
— O  
научилась O  
определять O  
голодных O  
рыбов O  
правильно O  
в O  
70 O  
% O  
случаев O  
. O
Итак O
, O
нам O  
нужно O  
выбрать O  
парсер O  
для O  
русского B-Lang  
языка I-Lang  
. O  
В O  
качестве O  
начальных O  
данных B-Object  
у O  
нас O  
есть O  
табличка O  
выше O  
с O  
лидирующим O  
Syntaxnet B-Application  
и O  
с	O
UDPipe	B-Application
2	I-Application
.	I-Application
0	I-Application
где	O
-	O
то	O
на	O
7	O
месте	O
.	O
GNMT B-Model
есть O
система O
машинного O
перевода B-Task
( B-Model
NMT I-Model
) I-Model
компании O
Google B-Organization
, O
которая O
использует O
нейросеть B-Model
(	O
ANN	B-Model
)	O
для O
повышения O
точности O
и O
скорости O
перевода O
, O
и O
в O
частности O
для O
создания O
лучших O
, O
более O
естественных O
вариантов O
перевода O
текста O
в O
Google B-Application
Translate I-Application
. O
Недавно O
рассказывал O  
о O  
том O
, O
как O  
делать O  
иерархически O  
датасет O  
из O  
Wikipedia B-Dataset  
( O  
Википедии O  
) O  
. O
Мы O
использовали O  
деревья B-Method  
решений I-Method  
для O  
этой O  
задачи B-Task  
классификации I-Task  
. O
Сегодня O
мы O  
расскажем O  
, O  
как O  
помогли O  
НПО B-Organization  
Энергомаш I-Organization  
создать O  
корпоративную O  
интеллектуальную O  
информационно O
- O
поисковую O
систему O  
( O  
КИИПС B-Application  
) O  
на O  
базе O  
ABBYY B-Organization  
Intelligent I-Application  
Search I-Application  
– O  
такую O  
же O  
удобную O  
и O  
быструю O  
, O  
как O  
популярные O  
поисковики O  
. O
Краткое O
резюме O
: O
Модель B-Model
ChatGPT I-Model
вышла O
в O
ноябре O
2022 O
- O
го O
и O
с O
технической O
точки O
зрения O
там O
не O
было O
никаких O
особых O
нововведений O
. O
Но O
зато O
у O
нее O
был O
удобный O
интерфейс O
взаимодействия O
и O
открытый O
публичный O
доступ O
— O
что O
немедленно O
породило O
огромную O
волну O
хайпа O
. O
А O
в O
нынешнем O
мире O
это O
главнее O
всего O
— O
так O
что O
языковыми B-Lang
моделями O
одномоментно O
начали O
заниматься O
вообще O
все O
вокруг O
! O
Кстати O
, O  
у O  
Игоря B-Person  
Котенкова I-Person  
( O  
одного O  
из O  
авторов O  
этой O  
статьи O  
) O  
есть O  
еще O  
один O  
лонгрид O  
на O  
Хабре B-InfoResource  
под O  
названием O  
« O  
ChatGPT B-Application  
как O  
инструмент O  
для O  
поиска O  
: O  
решаем O  
основную O  
проблему O  
» O  
, O  
в O  
котором O  
нюансы O  
машинного B-Science  
обучения I-Science  
разбираются O  
еще O  
более O  
подробно O  
. O
Чтобы O
размер O  
скрытых O  
слоев O  
и O  
размерность O  
эмбеддинга O  
были O  
разными O  
, O  
ALBERTa B-Model  
деконструирует O  
матрицу O  
эмбеддинга O  
на O  
2 O  
части O  
. O  
Это O  
увеличивает O  
размер O  
скрытого O  
слоя O  
, O  
не O  
меняя O  
фактического O  
размера O  
эмбеддинга O  
. O  
После O  
разложения O  
матрицы O  
, O  
ALBERT B-Model  
добавляет O  
линейный O  
или O  
полносвязный O  
слой O  
после O  
завершения O  
фазы O  
эмбеддинга O  
. O  
Это O  
гарантирует O  
, O  
что O  
размерность O  
размерности O  
эмбеддинга O  
будет O  
такой O  
же O  
правильной O  
. O  
Здесь O  
об O  
этом O  
рассказано O  
подробнее O  
. O
Важным O
аспектом O  
здесь O  
является O  
то O  
, O  
что O  
Nearby B-Application  
Share I-Application  
опирается O  
на O  
Google B-Organization  
Mobile I-Organization  
Services I-Organization  
( O  
GMS B-Organization  
) O  
, O  
а O  
это O  
означает O  
, O  
что O  
разработчик O  
системы O  
заменил O  
доступную O  
в O  
AOSP B-Environment  
функцию O  
проприетарной O  
службой O  
, O  
которая O  
не O  
является O  
частью O  
проекта O  
AOSP B-Environment  
. O
В O
полку O
LLM B-Model
прибыло O
: O
недавно O
специалисты O
из O
Французского B-Organization
национального I-Organization
центра I-Organizatio
научных I-Organization
исследований I-Organization
( O
French B-Organization
National I-Organization
Center I-Organization
for I-Organization
Scientific I-Organization
Research I-Organization
) O
объявили O
о O
релизе O
новой O
большой O
языковой B-Model
модели I-Model
под O
названием O
BLOOM B-Model
( O
расшифровывается O
как O
BigScience B-Science
Large I-Science
Open I-Science
- I-Science
science I-Science
Open I-Science
- I-Science
access I-Science
Multilingual I-Science
Language I-Science
Model I-Science
) O
. O
У O
классических O
transition O
- O
based O
parser O
возможны O
три O
операции O
, O
перечисленные O
выше O
: O
стрелка O
в O
одну O
сторону O
, O
стрелка O
в O
другую O
сторону O
и O
шифт O
. O
Есть O
еще O
операция O
Swap O
, O
в O
базовых O
архитектурах O
transition O
- O
based O
парсеров O
она O
не O
используется O
, O
Oно O
в O
UDPipe B-Application
включена O
. O
Swap O
возвращает O
второй O
элемент O
стека O
в O
буфер O
, O
чтобы O
взять O
потом O
из O
буфера O
следующий O
( O
в O
случае O
если O
они O
разнесены O
) O
. O
Это O
помогает O
пропустить O
некоторое O
количество O
слов O
и O
восстановить O
правильную O
связь O
. O
Так O  
родился O  
статистический O  
метод B-Method  
анализа I-Method  
текста O  
word2vec B-Method_ML  
(	O
англ	O
.	O
Word O  
to O  
vector O  
) O
. O
Весь O
Шекспир B-Person  
– O  
13 O  
увесистых O  
томов O
, O
которые O  
занимают O  
целую O  
полку O  
. O
Заметки O
об O  
NLP B-Subject  
( O
Natural B-Subject
Language I-Subject  
Processing I-Subject  
) O
. O
НКРЯ B-Dataset
– O
это O
совокупность O
русскоязычных O
текстов O
, O
Национальный B-Dataset
Корпус I-Dataset
Русского I-Dataset
Языка I-Dataset
в O
полном O
объёме O
. O
Давайте O
прикинем O  
: O  
собрание O  
сочинений O  
Уильяма B-Person  
Шекспира I-Person  
( O  
всех O  
его O  
пьес O  
, O  
сонетов O  
и O  
стихов O  
) O  
состоит O  
из O  
850 O
' O
000 O
слов O  
. O
Во O
- O
первых O
, O
конкретно O
для O
этого O
соревнования O
наиболее O
эффективный O
подход O
- O
это O
доразметка O
спанов O
тренировочных B-Dataset
данных I-Dataset
для O
задачи B-Task
NER I-Task
. O
Например O
, O
в O
TensorFlow B-Application
используется O
умножение O
справа O
, O
и O
матрица O
весов O
имеет O
размер O
( O
in O
, O
out O
) O
, O
в O
PyTorch B-Application
- O
умножение O
слева O
, O
и O
матрица O
весов O
имеет O
размер O
( O
out O
, O
in O
) O
. O
В O
третьей O
части O
( O
статья O
планируется O
) O
перейдем O
от O
метода B-Method
максимизации I-Method
правдоподобия I-Method
к O
байесовскому B-Method
выводу I-Method
и O
его O
различным O
приближениям O
, O
таким O
как O
метод B-Method
апостериорного I-Method
максимума I-Method
, O
методы B-Method
Монте I-Method
- I-Method
Карло I-Method
и O
вариационный B-Method
вывод I-Method
. O
Они O
отличаются O
хорошей O
сбалансированностью O
: O  
достаточно O  
высокий O  
уровень O  
чувствительности O  
одновременно O  
с O  
хорошим O  
соотношением O  
сигнал O  
/ O  
шум O  
и O  
уровнем O
AOP B-Metric
( O
Acoustic I-Metric  
Overload I-Metric  
Point I-Metric  
— O  
это O  
такой O  
аналог O  
максимального O  
звукового O  
давления O  
для O  
цифровых O  
микрофонов O  
) O  
. O
Ответ O
очень O  
прост O  
, O  
Docker B-Application  
compose I-Application  
нужен O  
для O  
быстрого O  
развертывания O  
приложения O  
, O  
например O  
, O  
перенос O  
приложения O  
на O  
другой O  
сервер O  
займет O  
несколько O  
минут O  
, O  
также O  
в O  
сочетании O  
с O  
kubernetes B-Application  
- O  
дает O  
превосходные O  
результаты O  
по O  
автоматизации O  
развертывания O  
, O  
масштабирования O  
и O  
координации O  
работы O  
нашего O  
приложения O  
в O  
условиях O  
кластера O  
. O
Привет O
! O  
Меня O  
зовут O  
Денис B-Person  
Кирьянов I-Person  
, O  
я O  
работаю O  
в O  
Сбербанке B-Organization  
и O  
занимаюсь O  
проблемами O  
обработки B-Task  
естественного I-Task  
языка I-Task  
( O  
NLP B-Task  
) O  
. O  
Однажды O  
нам O  
понадобилось O  
выбрать O  
синтаксический O  
парсер B-Model  
для O  
работы O  
с O  
русским B-Lang  
языком I-Lang  
. O  
Для O  
этого O  
мы O  
углубились O  
в O  
дебри O  
морфологии B-Science  
и O  
токенизации B-Task  
, O  
протестировали O  
разные O  
варианты O  
и O  
оценили O  
их O  
применение O  
. O  
Делимся O  
опытом O  
в O  
этом O  
посте O  
. O
У O 
RNNMorph B-Application 
возникает O 
своя O 
проблема O 
: O 
у O 
него O 
нет O 
токенизации O 
. O 
Если O 
Mystem B-Application 
умеет O 
токенизировать O 
сырой O 
текст O 
, O 
то O 
RNNMorph B-Application 
требует O 
на O 
входе O 
список O 
токенов O 
. O 
Чтобы O 
доехать O 
до O 
синтаксиса O 
, O 
придется O 
сначала O 
применить O 
какой O
- O
то O
внешний O 
токенизатор O 
, O 
потом O 
отдать O 
результат O 
RNNMorph B-Application 
и O 
только O 
потом O 
полученную O 
морфологию O 
скормить O 
синтаксическому O 
парсеру O 
. O
А O
теперь O
давайте O
еще O
вспомним O
, O
что O
обкатанная O
на O
GPT	B-Model
-	I-Model
1	I-Model
технология O
Трансформеров B-Model
оказалась O
на O
редкость O
удачной O
в O
плане O
масштабирования O
: O
она O
умеет O
работать O
с O
большими O
объемами O
данных O
и O
« O
массивными O
» O
моделями O
( O
состоящими O
из O
огромного O
числа O
параметров O
) O
гораздо O
эффективнее O
своих O
предшественников O
. O
Вы O
думаете O
о O
том O
же O
, O
о O
чем O
и O
я O
? O
Ну O
вот O
и O
ученые O
из O
OpenAI B-Organization
в O
2019 O
году O
сделали O
такой O
же O
вывод O
: O
« O
Пришло O
время O
пилить O
здоровенные O
языковые O
модели O
! O
» O
. O
В O
общем O
, O
было O
решено O
радикально O
прокачать O
GPT	B-Model
-	I-Model
2	I-Model
по O
двум O
ключевым O
направлениям O
: O
набор O
тренировочных O
данных O
( O
датасет B-Dataset
) O
и O
размер O
модели O
( O
количество O
параметров O
) O
. O
На O
тот O
момент O
не O
было O
каких O
‑ O
то O
специальных O
, O
больших O
и O
качественных O
, O
публичных O
наборов O
текстовых O
данных O
для O
тренировки O
языковых O
моделей O
— O
так O
что O
каждой O
команде O
специалистов O
по O
ИИ B-Science
приходилось O
извращаться O
согласно O
их O
собственной O
степени O
искорченности O
. O
Вот O
ребята O
из O
OpenAI B-Organization
и O
решили O
поступить O
остроумно O
: O
они O
пошли O
на O
самый O
популярный O
англоязычный B-Object
онлайн I-Object
‑ I-Object
форум I-Object
Reddit B-InfoResource
и O
тупо O
выкачали O
все O
гиперссылки O
из O
всех O
сообщений O
, O
имевших O
более O
трех O
лайков O
( O
я O
сейчас O
не O
шучу O
— O
научный O
подход O
, O
ну O
! O
) O
. O