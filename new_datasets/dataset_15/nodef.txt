Типичным O
методом B-Method
обучения I-Method
без O
учителя O
является O
кластеризация B-Method_ML
, O
благодаря O
которому O
обучающая O
выборка B-Dataset
разбивается O
на O
устойчивые O
группы O
или O
кластеры O
. O
Другой O
подход O
обучения B-Task
без O
учителя O
для O
текстов B-Object
называется O
тематическим B-Method_ML
моделированием I-Method_ML
( O
topic B-Method_ML
modeling I-Method_ML
) O
, O
позволяющим O
выявить O
в O
неразмеченных O
текстах B-Object
основные O
тематики O
. O
Если O
отказываемся O
от O
методов B-Method_ML
unsupervised I-Method_ML
learning I-Method_ML
, O
то O
логично O
обратиться O
к O
методам B-Method
обучения I-Method
с I-Method
учителем I-Method
( O
supervised B-Method_ML
learning I-Method_ML
) O
и O
в O
частности O
к O
классификации B-Task
. O
Результатом O
работы O
языковой B-Model
модели I-Model
являются O
эмбеддинги O
— O
это O
отображение O
из O
пространства O
слов O
в O
пространство O
векторов O
конкретной O
фиксированной O
длины O
, O
причем O
векторы O
, O
соответствующие O
близким O
по O
смыслу O
словам O
, O
будут O
расположены O
в O
новом O
пространстве O
рядом O
, O
а O
далекие O
по O
смыслу O
— O
далеко O
. O
При O
использовании O
TF-IDF B-Method
( O
например O
, O
вот O
) O
подхода O
с O
фильтром O
по O
частотам O
и O
логистической B-Model
регрессии I-Model
уже O
можно O
получить O
прекрасные O
результаты O
: O
изначально O
в O
краулер B-Application
отправлялись O
очень O
разные O
тексты O
, O
и O
модель O
прекрасно O
справляется O
. O
Используя O
TF-IDF B-Method_ML
с O
фильтром O
по O
частотам O
и O
логистической B-Method_ML
регрессией I-Method_ML
, O
уже O
можно O
достичь O
отличных O
результатов O
. O
Для O
каждой O
из O
популяций O
рассчитаем O
word2vec B-Model
расстояние O
до O
центра O
положительной O
обучающей O
выборки O
. O
Распределения O
можно O
разделить O
, O
и O
для O
оценки O
расстояния O
между O
распределениями O
в O
первую O
очередь O
логично O
обратиться O
к O
Дивергенции B-Metric
Кульбака-Лейблера I-Metric
( O
ДКЛ B-Metric
) O
. O