Типичным O
методом B-Method
обучения I-Method
без O
учителя O
является O
кластеризация O
, O
благодаря O
которому O
обучающая O
выборка O
разбивается O
на O
устойчивые O
группы O
или O
кластеры O
. O
Другой O
подход O
обучения O
без O
учителя O
для O
текстов O
называется O
тематическим O
моделированием B-Method_ML
( O
topic O
modeling O
) O
, O
позволяющим O
выявить O
в O
неразмеченных O
текстах O
основные O
тематики O
. O
Если O
отказываемся O
от O
методов O
unsupervised B-Method_ML
learning I-Method_ML
, O
то O
логично O
обратиться O
к O
методам O
обучения O
с O
учителем O
( O
supervised B-Method_ML
learning I-Method_ML
) O
и O
в O
частности O
к O
классификации O
. O
Результатом O
работы O
языковой B-Model
модели I-Model
являются O
эмбеддинги O
— O
это O
отображение O
из O
пространства O
слов O
в O
пространство O
векторов O
конкретной O
фиксированной O
длины O
, O
причем O
векторы O
, O
соответствующие O
близким O
по O
смыслу O
словам O
, O
будут O
расположены O
в O
новом O
пространстве O
рядом O
, O
а O
далекие O
по O
смыслу O
— O
далеко O
. O
При O
использовании O
TF-IDF O
( O
например O
, O
вот O
) O
подхода O
с O
фильтром O
по O
частотам O
и O
логистической O
регрессии O
уже O
можно O
получить O
прекрасные O
результаты O
: O
изначально O
в O
краулер O
отправлялись O
очень O
разные O
тексты O
, O
и O
модель O
прекрасно O
справляется O
. O
Используя O
TF-IDF B-Method
с O
фильтром O
по O
частотам O
и O
логистической B-Method_ML
регрессией I-Method_ML
, O
уже O
можно O
достичь O
отличных O
результатов O
. O
Для O
каждой O
из O
популяций O
рассчитаем O
word2vec B-Model
расстояние O
до O
центра O
положительной O
обучающей O
выборки B-Dataset
. O
Распределения O
можно O
разделить O
, O
и O
для O
оценки O
расстояния O
между O
распределениями O
в O
первую O
очередь O
логично O
обратиться O
к O
Дивергенции B-Metric
Кульбака-Лейблера I-Metric
( O
ДКЛ O
) O
. O