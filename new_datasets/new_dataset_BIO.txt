В	O
задаче	O
классификации	B-Task
использовался	O
logloss	B-Metric
,	O
вычисляемый	O
как	O
среднее	O
значение	O
метрики	O
sklearn	O
.	O
metrics	O
.	O
log_loss	O
по	O
классам	O
болезней	O
.	O
Также	O
на	O
описанном	O
материале	O
строятся	O
более	O
сложные	O
темы	O
,	O
такие	O
как	O
вариационные	B-Model
автокодировщики	I-Model
(	O
Kingma	B-Person
and	O
Welling	B-Person
,	O
2013	B-Date
)	O
,	O
нейробайесовские	B-Method
методы	I-Method
(	O
Müller	B-Person
et	O
al	O
.	O
,	O
2021	B-Date
)	O
и	O
даже	O
некоторые	O
теории	B-Method
сознания	I-Method
(	O
Friston	B-Person
et	O
al	O
.	O
,	O
2022	B-Date
)	O
.	O
В	O
этой	O
статье	O
я	O
расскажу	O
все	O
,	O
что	O
вам	O
нужно	O
знать	O
про	O
ALBERT	B-Model
,	O
RoBERTa	B-Model
,	O
и	O
DistilBERT	B-Model
.	O
Если	O
непонятно	O
по	O
названию	O
,	O
эти	O
модели	O
—	O
модифицированные	O
версии	O
оригинального	O
современного	O
трансформера	O
BERT	B-Model
.	O
Эти	O
три	O
модели	O
из	O
библиотеки	O
Hugging	B-Library
Face	I-Library
—	O
самые	O
популярные	O
на	O
сегодняшний	O
день	O
.	O
Я	O
рассмотрю	O
их	O
сходства	O
и	O
различия	O
по	O
сравнению	O
друг	O
с	O
другом	O
и	O
добавлю	O
фрагменты	O
кода	O
.	O
Они	O
покажут	O
,	O
как	O
вы	O
можете	O
их	O
использовать	O
.	O
Поэтому	O
MSE	B-Metric
,	O
в	O
сравнении	O
с	O
MAE	B-Metric
,	O
не	O
так	O
сильно	O
штрафует	O
несущественные	O
ошибки	O
,	O
но	O
сильнее	O
штрафует	O
большие	O
ошибки	O
.	O
Это	O
и	O
есть	O
тот	O
самый	O
переход	O
количества	O
в	O
качество	O
,	O
про	O
который	O
нам	O
когда	O
‑	O
то	O
твердил	O
старина	O
Карл	B-Person
Маркс	I-Person
.	O
Python	B-Environment
служит	O
главным	O
инструментом	O
в	O
руках	O
data	O
scientists	O
,	O
не	O
имеет	O
строгой	O
типизации	O
и	O
предназначен	O
для	O
быстрой	O
разработки	O
прототипов	O
или	O
написания	O
коротких	O
сценариев	O
или	O
скриптов	O
.	O
Крупные	O
компании	O
также	O
принимают	O
участие	O
в	O
разработке	O
библиотек	O
для	O
NLP	B-Science
,	O
как	O
например	O
NLP	B-Library
Architect	I-Library
от	O
Intel	B-Organization
или	O
PyTorch	B-Library
от	O
исследователей	O
из	O
Facebook	B-Organization
и	O
Uber	B-Organization
.	O
Казалось	O
бы	O
,	O
здесь	O
напрашивается	O
оценка	B-Task
точности	I-Task
(	O
accuracy	B-Metric
)	O
—	O
считаем	O
,	O
сколько	O
раз	O
мы	O
попали	O
из	O
общего	O
количества	O
случаев	O
.	O
Если	O
у	O
нас	O
есть	O
5	O
слов	O
и	O
для	O
4	O
мы	O
правильно	O
определили	O
вершину	O
,	O
то	O
получаем	O
80	B-Value
%	I-Value
.	O
Январь	B-Date
2022	I-Date
:	O
InstructGPT	B-Model
,	O
или	O
как	O
научить	O
робота	O
быть	O
политкорректым	O
.	O
На	O
самом	O
деле	O
,	O
увеличение	O
размеров	O
языковых	O
моделей	O
само	O
по	O
себе	O
еще	O
не	O
означает	O
,	O
что	O
они	O
будут	O
отвечать	O
на	O
запросы	O
именно	O
так	O
,	O
как	O
хочет	O
их	O
пользователь	O
.	O
Ведь	O
часто	O
мы	O
,	O
когда	O
формулируем	O
какой	O
‑	O
то	O
запрос	O
,	O
подразумеваем	O
очень	O
много	O
скрытых	O
условий	O
—	O
которые	O
в	O
коммуникации	O
между	O
людьми	O
считаются	O
сами	O
собой	O
разумеющимися	O
,	O
что	O
ли	O
.	O
А	O
вот	O
GPT	B-Model
-	I-Model
2	I-Model
никто	O
специально	O
таким	O
трюкам	O
не	O
учил	O
;	O
но	O
она	O
взяла	O
,	O
и	O
сама	O
неожиданно	O
и	O
уверенно	O
превзошла	O
своих	O
«	O
специализированных	O
»	O
предшественников	O
—	O
научилась	O
определять	O
голодных	O
рыбов	O
правильно	O
в	O
70	O
%	O
случаев	O
.	O
Итак	O
,	O
нам	O
нужно	O
выбрать	O
парсер	O
для	O
русского	B-Lang
языка	I-Lang
.	O
В	O
качестве	O
начальных	O
данных	O
у	O
нас	O
есть	O
табличка	O
выше	O
с	O
лидирующим	O
Syntaxnet	B-Application
и	O
с	O
UDPipe	B-Application
2	I-Application
.	I-Application
0	I-Application
где	O
-	O
то	O
на	O
7	O
месте	O
.	O
GNMT	B-Method
есть	O
система	B-Method
машинного	I-Method
перевода	I-Method
(	O
NMT	B-Method
)	O
компании	O
Google	B-Organization
,	O
которая	O
использует	O
нейросеть	O
(	O
ANN	B-Model
)	O
для	O
повышения	B-Task
точности	I-Task
и	I-Task
скорости	I-Task
перевода	I-Task
,	O
и	O
в	O
частности	O
для	O
создания	O
лучших	O
,	O
более	O
естественных	O
вариантов	O
перевода	O
текста	O
в	O
Google	B-Application
Translate	I-Application
.	O
Недавно	O
рассказывал	O
о	O
том	O
,	O
как	O
делать	O
иерархически	O
датасет	O
из	O
Wikipedia	B-InfoResource
(	O
Википедии	B-InfoResource
)	O
.	O
Мы	O
использовали	O
деревья	B-Method
решений	I-Method
для	O
этой	O
задачи	O
классификации	B-Task
.	O
Сегодня	O
мы	O
расскажем	O
,	O
как	O
помогли	O
НПО	B-Organization
Энергомаш	I-Organization
создать	O
корпоративную	B-Application
интеллектуальную	I-Application
информационно	I-Application
-	I-Application
поисковую	I-Application
систему	I-Application
(	O
КИИПС	B-Application
)	O
на	O
базе	O
ABBYY	B-Application
Intelligent	I-Application
Search	I-Application
–	O
такую	O
же	O
удобную	O
и	O
быструю	O
,	O
как	O
популярные	O
поисковики	O
.	O
Краткое	O
резюме	O
:	O
Модель	O
ChatGPT	B-Model
вышла	O
в	O
ноябре	O
2022	B-Date
-	O
го	O
и	O
с	O
технической	O
точки	O
зрения	O
там	O
не	O
было	O
никаких	O
особых	O
нововведений	O
.	O
Но	O
зато	O
у	O
нее	O
был	O
удобный	O
интерфейс	O
взаимодействия	O
и	O
открытый	O
публичный	O
доступ	O
—	O
что	O
немедленно	O
породило	O
огромную	O
волну	O
хайпа	O
.	O
А	O
в	O
нынешнем	O
мире	O
это	O
главнее	O
всего	O
—	O
так	O
что	O
языковыми	O
моделями	O
одномоментно	O
начали	O
заниматься	O
вообще	O
все	O
вокруг	O
!	O
Кстати	O
,	O
у	O
Игоря	B-Person
Котенкова	I-Person
(	O
одного	O
из	O
авторов	O
этой	O
статьи	O
)	O
есть	O
еще	O
один	O
лонгрид	O
на	O
Хабре	B-Application
под	O
названием	O
«	O
ChatGPT	B-Model
как	O
инструмент	O
для	O
поиска	O
:	O
решаем	O
основную	O
проблему	O
»	O
,	O
в	O
котором	O
нюансы	O
машинного	B-Science
обучения	I-Science
разбираются	O
еще	O
более	O
подробно	O
.	O
Чтобы	O
размер	O
скрытых	O
слоев	O
и	O
размерность	O
эмбеддинга	B-Object
были	O
разными	O
,	O
ALBERTa	B-Model
деконструирует	O
матрицу	O
эмбеддинга	B-Object
на	O
2	O
части	O
.	O
Это	O
увеличивает	O
размер	O
скрытого	O
слоя	O
,	O
не	O
меняя	O
фактического	O
размера	O
эмбеддинга	B-Object
.	O
После	O
разложения	O
матрицы	O
,	O
ALBERT	B-Model
добавляет	O
линейный	O
или	O
полносвязный	O
слой	O
после	O
завершения	O
фазы	O
эмбеддинга	B-Object
.	O
Это	O
гарантирует	O
,	O
что	O
размерность	O
размерности	O
эмбеддинга	B-Object
будет	O
такой	O
же	O
правильной	O
.	O
Здесь	O
об	O
этом	O
рассказано	O
подробнее	O
.	O
Важным	O
аспектом	O
здесь	O
является	O
то	O
,	O
что	O
Nearby	B-Application
Share	I-Application
опирается	O
на	O
Google	B-Application
Mobile	I-Application
Services	I-Application
(	O
GMS	B-Application
)	O
,	O
а	O
это	O
означает	O
,	O
что	O
разработчик	O
системы	O
заменил	O
доступную	O
в	O
AOSP	B-Activity
функцию	O
проприетарной	O
службой	O
,	O
которая	O
не	O
является	O
частью	O
проекта	O
AOSP	B-Activity
.	O
В	O
полку	O
LLM	B-Model
прибыло	O
:	O
недавно	O
специалисты	O
из	O
Французского	B-Organization
национального	I-Organization
центра	I-Organization
научных	I-Organization
исследований	I-Organization
(	O
French	B-Organization
National	I-Organization
Center	I-Organization
for	I-Organization
Scientific	I-Organization
Research	I-Organization
)	O
объявили	O
о	O
релизе	O
новой	O
большой	O
языковой	O
модели	O
под	O
названием	O
BLOOM	B-Model
(	O
расшифровывается	O
как	O
BigScience	B-Model
Large	I-Model
Open	I-Model
-	I-Model
science	I-Model
Open	I-Model
-	I-Model
access	I-Model
Multilingual	I-Model
Language	I-Model
Model	I-Model
)	O
.	O
У	O
классических	O
transition	B-Application
-	I-Application
based	I-Application
parser	I-Application
возможны	O
три	O
операции	O
,	O
перечисленные	O
выше	O
:	O
стрелка	O
в	O
одну	O
сторону	O
,	O
стрелка	O
в	O
другую	O
сторону	O
и	O
шифт	O
.	O
Есть	O
еще	O
операция	O
Swap	B-Method
,	O
в	O
базовых	O
архитектурах	O
transition	B-Application
-	I-Application
based	I-Application
парсеров	I-Application
она	O
не	O
используется	O
,	O
но	O
в	O
UDPipe	B-Application
включена	O
.	O
Swap	B-Method
возвращает	O
второй	O
элемент	O
стека	O
в	O
буфер	O
,	O
чтобы	O
взять	O
потом	O
из	O
буфера	O
следующий	O
(	O
в	O
случае	O
если	O
они	O
разнесены	O
)	O
.	O
Это	O
помогает	O
пропустить	O
некоторое	O
количество	O
слов	O
и	O
восстановить	O
правильную	O
связь	O
.	O
Так	O
родился	O
статистический	O
метод	O
анализа	O
текста	O
word2vec	B-Method
(	O
англ	O
.	O
Word	B-Method
to	I-Method
vector	I-Method
)	O
.	O
Весь	O
Шекспир	B-Person
–	O
13	O
увесистых	O
томов	O
,	O
которые	O
занимают	O
целую	O
полку	O
.	O
Заметки	O
об	O
NLP	B-Science
(	O
Natural	B-Science
Language	I-Science
Processing	I-Science
)	O
.	O
НКРЯ	B-Corpus
–	O
это	O
совокупность	O
русскоязычных	O
текстов	O
,	O
Национальный	B-Corpus
Корпус	I-Corpus
Русского	I-Corpus
Языка	I-Corpus
в	O
полном	O
объёме	O
.	O
Давайте	O
прикинем	O
:	O
собрание	B-Dataset
сочинений	I-Dataset
Уильяма	I-Dataset
Шекспира	I-Dataset
(	O
всех	O
его	O
пьес	B-Object
,	O
сонетов	B-Object
и	O
стихов	B-Object
)	O
состоит	O
из	O
850	O
'	O
000	O
слов	O
.	O
Во	O
-	O
первых	O
,	O
конкретно	O
для	O
этого	O
соревнования	O
наиболее	O
эффективный	O
подход	O
-	O
это	O
доразметка	B-Method
спанов	I-Method
тренировочных	I-Method
данных	I-Method
для	O
задачи	O
NER	B-Task
.	O
Например	O
,	O
в	O
TensorFlow	B-Library
используется	O
умножение	O
справа	O
,	O
и	O
матрица	O
весов	O
имеет	O
размер	O
(	O
in	O
,	O
out	O
)	O
,	O
в	O
PyTorch	B-Library
-	O
умножение	O
слева	O
,	O
и	O
матрица	O
весов	O
имеет	O
размер	O
(	O
out	O
,	O
in	O
)	O
.	O
В	O
третьей	O
части	O
(	O
статья	O
планируется	O
)	O
перейдем	O
от	O
метода	B-Method
максимизации	I-Method
правдоподобия	I-Method
к	O
байесовскому	B-Method
выводу	I-Method
и	O
его	O
различным	O
приближениям	O
,	O
таким	O
как	O
метод	B-Method
апостериорного	I-Method
максимума	I-Method
,	O
методы	B-Method
Монте	I-Method
-	I-Method
Карло	I-Method
и	O
вариационный	B-Method
вывод	I-Method
.	O
Они	O
отличаются	O
хорошей	O
сбалансированностью	O
:	O
достаточно	O
высокий	O
уровень	O
чувствительности	O
одновременно	O
с	O
хорошим	O
соотношением	O
сигнал	O
/	O
шум	O
и	O
уровнем	O
AOP	B-Metric
(	O
Acoustic	B-Metric
Overload	I-Metric
Point	I-Metric
—	O
это	O
такой	O
аналог	O
максимального	O
звукового	O
давления	O
для	O
цифровых	O
микрофонов	O
)	O
.	O
Ответ	O
очень	O
прост	O
,	O
Docker	B-Application
compose	I-Application
нужен	O
для	O
быстрого	O
развертывания	O
приложения	O
,	O
например	O
,	O
перенос	O
приложения	O
на	O
другой	O
сервер	O
займет	O
несколько	O
минут	O
,	O
также	O
в	O
сочетании	O
с	O
kubernetes	B-Application
-	O
дает	O
превосходные	O
результаты	O
по	O
автоматизации	O
развертывания	O
,	O
масштабирования	O
и	O
координации	O
работы	O
нашего	O
приложения	O
в	O
условиях	O
кластера	O
.	O
Привет	O
!	O
Меня	O
зовут	O
Денис	B-Person
Кирьянов	I-Person
,	O
я	O
работаю	O
в	O
Сбербанке	B-Organization
и	O
занимаюсь	O
проблемами	O
обработки	B-Science
естественного	I-Science
языка	I-Science
(	O
NLP	B-Science
)	O
.	O
Однажды	O
нам	O
понадобилось	O
выбрать	O
синтаксический	B-Application
парсер	I-Application
для	O
работы	O
с	O
русским	B-Lang
языком	I-Lang
.	O
Для	O
этого	O
мы	O
углубились	O
в	O
дебри	O
морфологии	B-Science
и	O
токенизации	B-Method
,	O
протестировали	O
разные	O
варианты	O
и	O
оценили	O
их	O
применение	O
.	O
Делимся	O
опытом	O
в	O
этом	O
посте	O
.	O
У	O
RNNMorph	B-Application
возникает	O
своя	O
проблема	O
:	O
у	O
него	O
нет	O
токенизации	B-Method
.	O
Если	O
Mystem	B-Application
умеет	O
токенизировать	B-Task
сырой	O
текст	O
,	O
то	O
RNNMorph	B-Application
требует	O
на	O
входе	O
список	O
токенов	B-Object
.	O
Чтобы	O
доехать	O
до	O
синтаксиса	B-Science
,	O
придется	O
сначала	O
применить	O
какой	O
-	O
то	O
внешний	O
токенизатор	B-Application
,	O
потом	O
отдать	O
результат	O
RNNMorph	B-Application
и	O
только	O
потом	O
полученную	O
морфологию	B-Science
скормить	O
синтаксическому	B-Application
парсеру	I-Application
.	O
А	O
теперь	O
давайте	O
еще	O
вспомним	O
,	O
что	O
обкатанная	O
на	O
GPT	B-Model
-	I-Model
1	I-Model
технология	B-Method
Трансформеров	I-Method
оказалась	O
на	O
редкость	O
удачной	O
в	O
плане	O
масштабирования	O
:	O
она	O
умеет	O
работать	O
с	O
большими	O
объемами	O
данных	O
и	O
«	O
массивными	O
»	O
моделями	O
(	O
состоящими	O
из	O
огромного	O
числа	O
параметров	O
)	O
гораздо	O
эффективнее	O
своих	O
предшественников	O
.	O
Вы	O
думаете	O
о	O
том	O
же	O
,	O
о	O
чем	O
и	O
я	O
?	O
Ну	O
вот	O
и	O
ученые	O
из	O
OpenAI	B-Organization
в	O
2019	B-Date
году	O
сделали	O
такой	O
же	O
вывод	O
:	O
«	O
Пришло	O
время	O
пилить	O
здоровенные	O
языковые	O
модели	O
!	O
»	O
.	O
В	O
общем	O
,	O
было	O
решено	O
радикально	O
прокачать	O
GPT	B-Model
-	I-Model
2	I-Model
по	O
двум	O
ключевым	O
направлениям	O
:	O
набор	B-Dataset
тренировочных	I-Dataset
данных	I-Dataset
(	O
датасет	B-Dataset
)	O
и	O
размер	O
модели	O
(	O
количество	O
параметров	O
)	O
.	O
На	O
тот	O
момент	O
не	O
было	O
каких	O
‑	O
то	O
специальных	O
,	O
больших	O
и	O
качественных	O
,	O
публичных	O
наборов	O
текстовых	O
данных	O
для	O
тренировки	O
языковых	O
моделей	O
—	O
так	O
что	O
каждой	O
команде	O
специалистов	O
по	O
ИИ	O
приходилось	O
извращаться	O
согласно	O
их	O
собственной	O
степени	O
испорченности	O
.	O
Вот	O
ребята	O
из	O
OpenAI	B-Organization
и	O
решили	O
поступить	O
остроумно	O
:	O
они	O
пошли	O
на	O
самый	O
популярный	O
англоязычный	O
онлайн	O
‑	O
форум	O
Reddit	B-Application
и	O
тупо	O
выкачали	O
все	O
гиперссылки	O
из	O
всех	O
сообщений	O
,	O
имевших	O
более	O
трех	O
лайков	O
(	O
я	O
сейчас	O
не	O
шучу	O
—	O
научный	O
подход	O
,	O
ну	O
!	O
)	O
.	O