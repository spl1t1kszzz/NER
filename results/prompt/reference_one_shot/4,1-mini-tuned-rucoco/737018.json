{
    "clusters": [["Slovo", "Slovo", "Slovo"], ["русский жестовый язык", "русского жестового языка", "РЖЯ", "РЖЯ", "языка", "РЖЯ", "жестовый язык", "Русском жестовом языке", "РЖЯ", "РЖЯ", "Русского жестового языка", "РЖЯ", "жестового языка", "русского жестового языка"], ["Habr", "corporate blog"], ["Всем", "мы", "нам", "мы", "мы", "мы"], ["непростой задачи распознавания русского жестового языка (РЖЯ) для слабослышащих", "задачей распознавания РЖЯ"], ["открытом доступе", "открытый доступ"], ["небольшую часть нашего датасета", "часть датасета"], ["статье", "статье", "статьи"], ["особенности РЖЯ", "особенности", "жестового языка"], ["проблемах и сложностях самого языка, и процессе его сбора и разметки", "которой также способствует частичной социальной изоляции"], ["где искали экспертов", "как нам в итоге удалось собрать самый большой и разнородный жестовый датасет для РЖЯ"], ["набора предобученных нейронных сетей", "сетей"], ["небольшое приложение, демонстрирующее распознавание жестового языка", "демо"], ["Часть датасета", "которую мы назвали Slovo", "Он"], ["видео", "видео", "которых"], ["не происходит жестовых событий", "«не жест»"], ["тестовую (test) выборки с 15000 и 5000 сэмплами соответственно", "выборки"], ["«не жесты»", "не жест"], ["Видео", "Видео", "видео", "видео", "видео", "Видео", "видео", "видео", "видео", "видео", "видео", "видео", "видео", "видео", "видео", "видео", "видео", "видео", "видео", "видео"], ["экспертов", "экспертов", "экспертов"], ["тестовая выборка", "которая"], ["обучающая", "с помощью 112 экспертов"], ["между обучающей и тестовой выборками", "эта выборка"], ["выборка", "выборками"], ["версиях", "Исходный", "Обработанный"], ["человек", "который"], ["на котором представлены основные статистики по датасету Slovo", "На первом графике показаны распределения по длительности видео, на втором и третьем распределения по количеству записанных видео на каждого эксперта. А на последнем изображена диаграмма распределения качества видеозаписей.Статистики датасетаКраудсорсингДля сбора и разметки РЖЯ мы использовали две российские краудсорсинг-платформы: Yandex.Toloka, на которой мы только собирали видео для датасета, и ABC Elementary, где, ввиду высокой квалификации разметчиков, проходили остальные этапы краудсорсинга — сбор, валидация и разметка РЖЯ. Также использование двух платформ позволяет получить две непересекающиеся аудитории знающих РЖЯ, что повышает качество финальных данных.Полный цикл создания датасета состоит из нескольких этапов:Экзамен — выявление группы пользователей, знающих РЖЯ,Сбор данных — получение необработанного датасета видео,Валидация — проверка качества датасета, удаление дубликатов и плохих данных (низкая кадровая частота или разрешение),Разметка — выявление участка видео с требуемым событием жеста + финальная агрегация результатов,Фильтрация — финальный постпроцессинг для подготовки чистого датасета.РЖЯ пайплайнЭкзаменЭкзамен является очевидной стадией сбора качественного датасета. Он позволяет отфильтровать из большой группы пользователей требуемых экспертов. Наш экзамен был относительно прост, но для не знакомых с РЖЯ людей пройти его было затруднительно. Пример экзамена на знание РЖЯПользователям предоставлялось от 10 до 15 видео, которые необходимо было посмотреть и классифицировать правильный жест на них. В итоге интерес к заданию проявили около 45 тысяч человек, а полностью экзамен прошли 25 тысяч пользователей, из которых около 400 пользователей получили высокий навык >= 90%. Экспертов с навыком 90% и выше мы привлекли для стадии валидации и разметки РЖЯ, а экспертов с навыком 80% и выше попросили записывать жесты в проекте майнинга данных. На следующем рисунке представлены графики распределения навыка знания РЖЯ в наших проектах.Распределение по экспертамК сожалению, это только общая статистика навыка на краудсорсинг-площадке. Некоторые пользователи получают навык и не выполняют задания вообще, либо выполняют только какую-то часть и теряют интерес к проекту (независимо от мотивирующих факторов, высокой стоимости заданий и т. д.). В конечном счете, в проекте записи РЖЯ приняло участие около 200 человек.Сбор данныхНа этой стадии мы попросили квалифицированных носителей РЖЯ записать видео с тем или иным жестом. К сбору данных допускались пользователи, прошедшие экзамен с навыком не менее 80%. Сбор данных интуитивно понятен и максимально прост — пользователю предоставляется слово из РЖЯ и видео-шаблон, на котором показан нужный жест. Нужно записать жест по аналогии и отправить его через краудсорсинг-площадку. Прогресс-бар выполнения заданий в одном из пулов на стадии сбора выглядит следующим образом:Прогресс выполнения задания на Yandex.TolokaВалидацияНесмотря на то, что мы отобрали группу носителей РЖЯ, это не избавляет нас от проблемы некачественного выполнения заданий, поэтому без стадии валидации обойтись нельзя. На этом этапе мы показывали каждое записанное видео отдельной группе людей, которые должны были определить, правильно оно записано или нет. Критерии правильности приемки достаточно простые:Камера исполнителя не дрожит;Жест должен быть выполнен верно;Руки не выходят за кадр в процессе выполнения жеста.К проекту валидации допускались пользователи, прошедшие экзамен с навыком не менее 90%. Чтобы повысить качество сбора датасета, каждое видео на этапе валидации проверяли от 3 до 5 независимых экспертов. По умолчанию уровень перекрытия равен 3, а если ответы экспертов не согласованы — перекрытие динамически увеличивалось сначала до 4, а потом, в случае необходимости, до 5 (этот процесс происходит автоматически на краудсорсинг площадке). Финальное решение агрегировано по «мнению большинства».Кроме того, мы использовали набор эвристик для контроля качества записи датасета и ввели дополнительные блокировки исполнителей на краудсорсинг площадке: 1) временный бан за быстрые ответы или пропуски; 2) временный или постоянный бан за неверные ответы по результатам валидации. На этой же стадии мы проверяли видео на качество записи и отбраковывали записи в плохом разрешении (min_side < 320), с низкой кадровой частотой (fps < 15), и слишком короткие записи длиной менее 1 секунды. Здесь же мы удаляли дубликаты видео, высчитывая phash отдельно взятых кадров.Также мы периодически проверяли качество ответов пользователей и блокировали плохих экспертов на постоянной основе, если процент правильно выполненных заданий был ниже 50% (более половины их ответов отклонены на этапе валидации).РазметкаНа этапе разметки мы отдавали видео пользователям, которые должны были определить начало и конец события. Перед экспертами также был шаблон правильного выполнения жеста. Перекрытие на этапе разметки строго фиксировано и равно 3, то есть каждое видео размечено тремя независимыми пользователями. Это позволяет получить качественную усредненную разметку и не волноваться за уверенность ответов пользователей (для случая, когда перекрытие = 1).После сбора разметки путем несложного алгоритма усреднения для каждого видео появляется размеченная область, на которой выполняется жест из РЖЯ. Записанные видео обрезаются по границам этой области и формируют финальный датасет. На следующем рисунке представлен примерный пайплайн агрегации разметки:Собрать разметку от N = 3 пользователейРазделить на группы начало и конец разметкиПроверить максимальную разницу между границами в каждой группеВ случае успеха усреднить границыАгрегация разметки видеоК нашему удивлению, качество разметки получилось максимально высоким, а из 100K видео не удалось агрегировать только 6.В дополнение к этому, мы разметили обработанный датасет с помощью Mediapipe — на каждом кадре размечены кисти рук. Это может повысить качество распознавания жестового языка, путем добавления алгоритмических эвристик.ФильтрацияНа этой стадии мы формируем финальный датасет. Процесс фильтрации состоял из нескольких этапов:Убираем неподходящие видео по параметрам width, height, fps, length;Убираем составные и сложные жесты;Отделяем дактиль от слов (пример: буква «я» и слово «Я»);По разметке нарезаем кадры с жестами из исходных видео;Ускоряем слишком медленные видео*Разбиваем датасет на обучающую и тестовую выборки по user_id.* — мы обнаружили, что для некоторых видео, выполнение жеста было слишком медленным. поэтому для каждого класса мы посчитали среднюю длину видео и пропорционально ускорили самые длинные видео до среднего значения.Эксперименты и демоНа нашем датасете мы обучили ряд нейронных сетей, большая часть из которых основана на современном подходе с Visual Transformers. Предварительно сетки были обучены на датасете Kinetics. Очевидно, что задача распознавания РЖЯ должна выполняться в режиме реального времени, в идеале на портативных и мобильных устройствах. Однако, далеко не все современные подходы могут обеспечить реал-тайм. Мы провели серию экспериментов с небольшими моделями типа Swin-small и Swin-tiny, но они показали очень плохие метрики. В качестве бейзлайна выбрали сверточную архитектуру на базе ResNet3D-50 и две тяжелые модели Swin-large c головой I3D и mVITv2-small. Поскольку жесты РЖЯ можно показывать любой рукой, в процессе обучения мы добавили горизонтальное отражение в качестве базовой аугментации.Также мы провели серию экспериментов с разным окном сэмплирования входных данных — 16, 32, 48 и 64 кадров. Поскольку эксперименты с размером окна в 64 кадра давали очень плохие метрики — мы не стали включать их в финальные результаты. Помимо этого, мы прореживали исходные видео с параметром децимации от 1 до 4 (в случае d = 1 видео не меняется). Эксперименты с d > 4 также показывали очень плохие метрики, поскольку пропускалось очень много кадров и даже визуально распознать в таком разреженном потоке какой-либо жест было невозможно. В качестве основной метрики мы выбрали mean accuracy. На следующем графике представлены результаты метрик для моделей ResNet3D-50 и Swin-large.Метрики для ResNet3D и Swin-LargeПодробное описание обучения моделей можно посмотреть в нашей статье.В репозитории вы найдете код для запуска ONNX и Pytorch моделей. Обращаем ваше внимание, что на CPU время инференса достаточно велико, и получить реал-тайм распознавание не получится. Если у вас есть GPU - запускайте модели с использованием видеокарт.Дальнейшие планыНа этом наши эксперименты не заканчиваются, и мы планируем развивать тему распознавания русского жестового языка по разным направлениям. Вот примерный список открытых проблем для жестовых языков, включая русский:Изучить различные диалекты РЖЯ и найти закономерности между ними для русского жестового языка и языков СНГ группы для создания универсального решения.Расширение жестовой корзины за счет добавления новых классов и увеличения числа видео на класс (сейчас в нашей команде идет процесс сбора датасета на около 3000 слов, в среднем по 50 видео на класс).Решение проблемы конструирования законченных предложений, определение пауз между словами и предложениями, распознавание составных жестов, решение задачи обратной лемматизации.Переход от текстовых предсказаний в домен звука (задача — video2speech).Переход в мульти-модальный домен с возможностью распознавания слов не только по жестам, но и по губам, мимике и позе человека.Решение обратной задачи text2video — это генерация видео по текстовым описаниям жестов (виртуальный сурдопереводчик)Мульти-язычный жестовый язык, поиск закономерностей в жестовых языках разных стран мира.ЗаключениеВ этой статье мы представили датасет Slovo и набор обученных на нем нейронных сетей для распознавания русского жестового языка. Датасет и модели распространяются под переработанной версией лицензии Creative Commons Corporation (Attribution-ShareAlike 4.0). Следите за обновлениями, обязательно будем публиковать успехи в этом направлении.Будем очень признательны за фидбек. Если среди вас или ваших знакомых есть носители РЖЯ, которые готовы поучаствовать в проекте — пишите нам, мы подробнее расскажем о задачах!АвторыАлександр Капитанов - @hukenovsКарина Кванчиани - @karinakvanchianiАлександр Нагаев - @nagaditЕлизавета Петрова - @kleinsbotleОтдельное спасибо дата-инженерам - Саутину Александру и Суровцеву Петру, которые 24/7 следят за качеством наших данных.СсылкиarXivGithub Gitlab KaggleТакже у нашей команды появился телеграм-канал, где мы будем рассказывать о результатах нашей работы, делиться идеями и даже факапами. Подписывайтесь. Tags: распознавание жестоврусский жестовый языкРЖЯнейронные сетиобработка видеомашинное обучениеслабослышащиеглубокое обучениеdata science Hubs: SberDevices corporate blogData MiningImage processingMachine learningArtificial Intelligence"], ["сложность в создании подходящего набора данных", "проблему"], ["нашего датасета", "этого датасета"], ["уникальных классов", "классов"], ["жестов", "жестов"], ["400 видео", "которых"], ["тренировочную (train), и тестовую (test) выборки с 15000 и 5000 сэмплами соответственно", "выборки"], ["“не жесты”", "не жест"], ["сэмплами", "выборками"], ["194 экспертов", "экспертов"], ["экзамен на знание РЖЯ", "экзамен"], ["не знакомых с РЖЯ людей", "людей"], ["жесты в проекте майнинга данных", "жесты"], ["графики распределения навыка знания РЖЯ в наших проектах", "Распределение по экспертам"], ["общая статистика навыка на краудсорсинг-площадке", "это"], ["проекте записи РЖЯ", "проекте"], ["носителей РЖЯ", "носителей РЖЯ"], ["жестом", "нужный жест"], ["задания", "задания"], ["Yandex.Toloka", "Yandex.Toloka"], ["группе людей", "которые"], ["некачественного выполнения заданий", "проблемы некачественного выполнения заданий"], ["исполнителя", "Камера исполнителя"], ["90%", "90%"], ["ответов экспертов", "ответы экспертов"], ["этот процесс", "процесс"], ["исполнителей", "исполнителей"], ["бан за быстрые ответы или пропуски", "временный бан за быстрые ответы или пропуски"], ["неверные ответы по результатам валидации", "временный или постоянный бан за неверные ответы по результатам валидации"], ["качество записи", "качество записи датасета"], ["плохом разрешении", "плохом разрешении"], ["низкой кадровой частотой", "низкой кадровой частотой"], ["короткие записи длиной менее 1 секунды", "слишком короткие записи длиной менее 1 секунды"], ["дубликаты видео", "дубликаты видео"], ["отдельно взятых кадров", "кадров"], ["качество ответов пользователей", "качество ответов пользователей"], ["плохих экспертов", "плохих экспертов"], ["процент правильно выполненных заданий", "процент правильно выполненных заданий"], ["ответов", "их ответов"], ["видео", "видео"], ["начало и конец события", "начала и конца жеста"], ["экспертами", "независимыми пользователями"], ["уверенность ответов пользователей", "уверенность ответов пользователей"], ["случая", "случая"], ["разметки", "разметки"], ["размеченная область", "области"], ["этой области", "этой области"], ["записанные видео", "Записанные видео"], ["примерный пайплайн агрегации разметки", "пайплайн агрегации разметки"], ["N", "3"], ["группы", "группы"], ["разметки", "разметки"], ["границами", "границ"], ["усреднить границы", "усреднить границы"], ["Агрегация разметки видео", "Агрегация разметки видео"], ["качество разметки", "качество разметки"], ["максимально высоким", "максимально высоким"], ["100K видео", "100K видео"], ["6", "6"], ["обработанный датасет", "обработанный датасет"], ["на каждом кадре", "на каждом кадре"], ["кисти рук", "кисти рук"], ["качество распознавания жестового языка", "качество распознавания жестового языка"], ["эвристик", "эвристик"], ["финальный датасет", "финальный датасет"], ["процесса фильтрации", "процесса фильтрации"], ["этапов", "этапов"], ["составные и сложные жесты", "составные и сложные жесты"], ["дактиль", "дактиль"], ["слов", "слов"], ["разметке", "разметке"], ["кадры с жестами из исходных видео", "кадры с жестами из исходных видео"], ["слишком медленные видео*", "слишком медленные видео*"], ["обучающую и тестовую выборки по user_id", "выборки"], ["видео", "видео"], ["жеста", "жеста"], ["серию экспериментов с небольшими моделями типа Swin-small и Swin-tiny", "серии экспериментов"], ["очень плохие метрики", "очень плохие метрики"], ["бэйзлайна", "бэйзлайна"], ["две тяжелые модели Swin-large c головой I3D и mVITv2-small", "две тяжелые модели Swin-large c головой I3D и mVITv2-small"], ["любый рукой", "любой рукой"], ["горизонтальное отражение", "горизонтальное отражение"], ["серии экспериментов с разным окном сэмплирования входных данных — 16, 32, 48 и 64 кадров", "серии экспериментов"], ["финальные результаты", "финальные результаты"], ["исходные видео", "исходные видео"], ["параметром децимации от 1 до 4", "параметром децимации от 1 до 4"], ["видео", "видео"], ["эксперименты с d > 4", "эксперименты с d > 4"], ["очень плохие метрики", "очень плохие метрики"], ["кадров", "кадров"], ["видео", "видео"], ["основной метрики", "основной метрики"], ["результаты метрик для моделей ResNet3D-50 и Swin-large", "результатов метрик для моделей ResNet3D-50 и Swin-large"], ["моделей", "моделей"], ["статье", "нашей статье"], ["репозитории", "репозитории"], ["CPU", "CPU"], ["реал-тайм распознавание", "реал-тайм распознавание"], ["GPU", "GPU"], ["модели", "модели"], ["русского жестового языка", "русского жестового языка"], ["открытых проблем для жестовых языков", "открытых проблем для жестовых языков"], ["них", "ними"], ["русского жестового языка", "русского жестового языка"], ["языков СНГ группы", "группы"], ["сейчас", "сейчас"], ["нашей команде", "нашей команде"], ["классах", "класс"], ["виртуальный сурдопереводчик", "виртуальный сурдопереводчик"], ["жестовый язык", "жестовых языках"], ["этой статье", "в этой статье"], ["Slovo", "Slovo"], ["нейронных сетей", "нейронных сетей"], ["Датасет", "Датасет"], ["модели", "модели"], ["фидбек", "фидбек"], ["вас", "вас"], ["ваших знакомых", "ваших знакомых"], ["носители РЖЯ", "носители РЖЯ"], ["мы", "мы"], ["АвторыАлександр Капитанов", "Александр Капитанов"], ["Карина Кванчиани", "Карина Кванчиани"], ["Александр Нагаев", "Александр Нагаев"], ["Елизавета Петрова", "Елизавета Петрова"], ["дата-инженерам - Саутину Александру и Суровцеву Петру", "Саутину Александру и Суровцеву Петру"], ["качеством наших данных", "наших данных"], ["телеграм-канал", "телеграм-канал"], ["мы", "мы"]]
}