Перед O
переходом O
к O
самим O
метрикам B-Metric
необходимо O
ввести O
важную O
концепцию O
для O
описания O
этих O
метрик B-Metric
в O
терминах O
ошибок O
классификации O
— O
confusion B-Metric
matrix I-Metric
( O
матрица O
ошибок O
) O
. O
Интуитивно O
понятной O
, O
очевидной O
и O
почти O
неиспользуемой O
метрикой B-Metric
является O
accuracy B-Metric
— O
доля O
правильных O
ответов O
алгоритма O
. O
Для O
оценки O
качества O
работы O
алгоритма O
на O
каждом O
из O
классов O
по O
отдельности O
введем O
метрики O
precision B-Metric
( O
точность O
) O
и O
recall B-Metric
( O
полнота O
) O
. O
Precision B-Metric
можно O
интерпретировать O
как O
долю O
объектов O
, O
названных O
классификатором O
положительными O
и O
при O
этом O
действительно O
являющимися O
положительными O
, O
а O
recall B-Metric
показывает O
, O
какую O
долю O
объектов O
положительного O
класса O
из O
всех O
объектов O
положительного O
класса O
нашел O
алгоритм O
. O
F-мера B-Metric
достигает O
максимума O
при O
полноте B-Metric
и O
точности B-Metric
, O
равными O
единице O
, O
и O
близка O
к O
нулю O
, O
если O
один O
из O
аргументов O
близок O
к O
нулю O
. O
Одним O
из O
способов O
оценить O
модель B-Model
в O
целом O
, O
не O
привязываясь O
к O
конкретному O
порогу O
, O
является O
AUC-ROC B-Metric
( O
или O
ROC B-Metric
AUC I-Metric
) O
— O
площадь O
( O
Area O
Under O
Curve O
) O
под O
кривой O
ошибок O
( O
Receiver O
Operating O
Characteristic O
curve O
) O
. O
Интуитивно O
можно O
представить O
минимизацию O
logloss B-Metric
как O
задачу B-Task
максимизации O
accuracy B-Metric
путем O
штрафа O
за O
неверные O
предсказания O
. O